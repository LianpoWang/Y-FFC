import torch
import torch.nn as nn




class unet(nn.Module):
    def __init__(self):
        super(unet, self).__init__()
        self.preconv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3), padding=1, dilation=1)
        self.prebn1 = nn.BatchNorm2d(num_features=32)
        self.prerelu1 = nn.LeakyReLU()
        self.preconv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=2, dilation=2)
        self.prebn2 = nn.BatchNorm2d(num_features=32)
        self.prerelu2 = nn.LeakyReLU()
        self.preconv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=3, dilation=3)
        self.prebn3 = nn.BatchNorm2d(num_features=32)
        self.prerelu3 = nn.LeakyReLU()
        self.preconv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=2, dilation=2)
        self.prebn4 = nn.BatchNorm2d(num_features=32)
        self.prerelu4 = nn.LeakyReLU()
        self.preconv5 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), padding=1, dilation=1)
        self.prebn5 = nn.BatchNorm2d(num_features=32)
        self.prerelu5 = nn.LeakyReLU()

        self.conv1_1 = nn.Conv2d(in_channels=32,out_channels=32, kernel_size=(3,3), padding=1)
        self.bn1_1 = nn.BatchNorm2d(num_features=32)
        self.relu1_1 = nn.LeakyReLU()
        self.conv1_2 = nn.Conv2d(in_channels=32,out_channels=32, kernel_size=(3, 3), padding=1)
        self.bn1_2 = nn.BatchNorm2d(num_features=32)
        self.relu1_2 = nn.LeakyReLU()
        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.drop1 = nn.Dropout(0.1)

        self.conv2_1 = nn.Conv2d(in_channels=32,out_channels=64, kernel_size=(3,3), padding=1)
        self.bn2_1 = nn.BatchNorm2d(num_features=64)
        self.relu2_1 = nn.LeakyReLU()
        self.conv2_2 = nn.Conv2d(in_channels=64,out_channels=64, kernel_size=(3,3), padding=1)
        self.bn2_2 = nn.BatchNorm2d(num_features=64)
        self.relu2_2 = nn.LeakyReLU()
        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.drop2 = nn.Dropout(0.1)

        self.conv3_1 = nn.Conv2d(in_channels=64,out_channels=128, kernel_size=(3,3), padding=1)
        self.bn3_1 = nn.BatchNorm2d(num_features=128)
        self.relu3_1 = nn.LeakyReLU()
        self.conv3_2 = nn.Conv2d(in_channels=128,out_channels=128, kernel_size=(3,3), padding=1)
        self.bn3_2 = nn.BatchNorm2d(num_features=128)
        self.relu3_2 = nn.LeakyReLU()
        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.drop3 = nn.Dropout(0.1)

        self.conv4_1 = nn.Conv2d(in_channels=128,out_channels=256, kernel_size=(3,3), padding=1)
        self.bn4_1 = nn.BatchNorm2d(num_features=256)
        self.relu4_1 = nn.LeakyReLU()
        self.conv4_2 = nn.Conv2d(in_channels=256,out_channels=256, kernel_size=(3,3), padding=1)
        self.bn4_2 = nn.BatchNorm2d(num_features=256)
        self.relu4_2 = nn.LeakyReLU()
        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.drop4 = nn.Dropout(0.1)

        self.conv5_1 = nn.Conv2d(in_channels=256,out_channels=512, kernel_size=(3,3), padding=1)
        self.bn5_1 = nn.BatchNorm2d(num_features=512)
        self.relu5_1 = nn.LeakyReLU()
        self.conv5_2 = nn.Conv2d(in_channels=512,out_channels=512, kernel_size=(3,3), padding=1)
        self.bn5_2 = nn.BatchNorm2d(num_features=512)
        self.relu5_2 = nn.LeakyReLU()
        self.maxpool5 = nn.MaxPool2d(kernel_size=2, stride=2)

        #为了使大小变为64*64，将kernel_size设置成4

        self.up6 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=(2, 2),stride=2)
        self.conv6_1 = nn.Conv2d(in_channels=512,out_channels=256, kernel_size=(3,3), padding=1)
        self.bn6_1 = nn.BatchNorm2d(num_features=256)
        self.relu6_1 = nn.LeakyReLU()
        self.conv6_2 = nn.Conv2d(in_channels=256,out_channels=256, kernel_size=(3,3), padding=1)
        self.bn6_2 = nn.BatchNorm2d(num_features=256)
        self.relu6_2 = nn.LeakyReLU()

        self.up7 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=(2, 2), stride=2)
        self.conv7_1 = nn.Conv2d(in_channels=256,out_channels=128, kernel_size=(3,3), padding=1)
        self.bn7_1 = nn.BatchNorm2d(num_features=128)
        self.relu7_1 = nn.LeakyReLU()
        self.conv7_2 = nn.Conv2d(in_channels=128,out_channels=128, kernel_size=(3,3), padding=1)
        self.bn7_2 = nn.BatchNorm2d(num_features=128)
        self.relu7_2 = nn.LeakyReLU()

        self.up8 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=(2, 2), stride=2)
        self.conv8_1 = nn.Conv2d(in_channels=128,out_channels=64, kernel_size=(3,3), padding=1)
        self.bn8_1 = nn.BatchNorm2d(num_features=64)
        self.relu8_1 = nn.LeakyReLU()
        self.conv8_2 = nn.Conv2d(in_channels=64,out_channels=64, kernel_size=(3,3), padding=1)
        self.bn8_2 = nn.BatchNorm2d(num_features=64)
        self.relu8_2 = nn.LeakyReLU()

        self.up9 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=(2, 2), stride=2)
        self.conv9_1 = nn.Conv2d(in_channels=64,out_channels=32, kernel_size=(3,3), padding=1)
        self.bn9_1 = nn.BatchNorm2d(num_features=32)
        self.relu9_1 = nn.LeakyReLU()
        self.conv9_2 = nn.Conv2d(in_channels=32,out_channels=32, kernel_size=(3,3), padding=1)
        self.bn9_2 = nn.BatchNorm2d(num_features=32)
        self.relu9_2 = nn.LeakyReLU()

        self.up10 = nn.ConvTranspose2d(in_channels=32, out_channels=1, kernel_size=(2, 2), stride=2)
        self.conv10 = nn.Conv2d(in_channels=1,out_channels=32, kernel_size=(3,3), padding=1)
        self.maxpool10 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv11 = nn.Conv2d(in_channels=32,out_channels=64, kernel_size=(3,3), padding=1)
        self.maxpool11 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv12 = nn.Conv2d(in_channels=64,out_channels=128, kernel_size=(3,3), padding=1)
        self.maxpool12 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv13 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=1,dilation=1)
        self.relu13= nn.LeakyReLU()
        self.conv14 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=2,dilation=2)
        self.relu14 = nn.LeakyReLU()
        self.conv15 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=3,dilation=3)
        self.relu15 = nn.LeakyReLU()
        self.conv16 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=2,dilation=2)
        self.relu16 = nn.LeakyReLU()
        self.conv17 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3, 3), padding=1,dilation=1)
        self.relu17 = nn.LeakyReLU()
        self.conv18 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=(4, 4), stride=2, padding=1)
        self.conv19 = nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=(4, 4), stride=2, padding=1)
        self.conv20 = nn.ConvTranspose2d(in_channels=32, out_channels=1, kernel_size=(4, 4), stride=2, padding=1)



    def forward(self, x):
        preconv1=self.prerelu1(self.prebn1(self.preconv1(x)))
        preconv2 = self.prerelu2(self.prebn2(self.preconv2(preconv1)))
        preconv3 = self.prerelu3(self.prebn3(self.preconv3(preconv2)))
        preconv4 = self.prerelu4(self.prebn4(self.preconv4(preconv3)))
        preconv5 = self.prerelu5(self.prebn5(self.preconv5(preconv4)))
        # print("pre",preconv5.shape)

        conv1_1_out = self.conv1_1(preconv5)
        conv1_1_out = self.bn1_1(conv1_1_out)
        conv1_1_out = self.relu1_1(conv1_1_out)
        conv1_2_out = self.conv1_2(conv1_1_out)
        conv1_2_out = self.bn1_2(conv1_2_out)
        conv1_2_out = self.relu1_2(conv1_2_out)
        maxpool1_out = self.maxpool1(conv1_2_out)
        # print("maxpool1:",maxpool1_out.shape)


        conv2_1_out = self.conv2_1(maxpool1_out)
        conv2_1_out = self.bn2_1(conv2_1_out)
        conv2_1_out = self.relu2_1(conv2_1_out)
        conv2_2_out = self.conv2_2(conv2_1_out)
        conv2_2_out = self.bn2_2(conv2_2_out)
        conv2_2_out = self.relu2_2(conv2_2_out)
        maxpool2_out = self.maxpool2(conv2_2_out)
        # print("maxpool2:",maxpool2_out.shape)

        conv3_1_out = self.conv3_1(maxpool2_out)
        conv3_1_out = self.bn3_1(conv3_1_out)
        conv3_1_out = self.relu3_1(conv3_1_out)
        conv3_2_out = self.conv3_2(conv3_1_out)
        conv3_2_out = self.bn3_2(conv3_2_out)
        conv3_2_out = self.relu3_2(conv3_2_out)
        maxpool3_out = self.maxpool3(conv3_2_out)
        # print("maxpool3:",maxpool3_out.shape)

        conv4_1_out = self.conv4_1(maxpool3_out)
        conv4_1_out = self.bn4_1(conv4_1_out)
        conv4_1_out = self.relu4_1(conv4_1_out)
        conv4_2_out = self.conv4_2(conv4_1_out)
        conv4_2_out = self.bn4_2(conv4_2_out)
        conv4_2_out = self.relu4_2(conv4_2_out)
        maxpool4_out = self.maxpool4(conv4_2_out)
        # print("maxpool4:",maxpool4_out.shape)

        conv5_1_out = self.conv5_1(maxpool4_out)
        conv5_1_out = self.bn5_1(conv5_1_out)
        conv5_1_out = self.relu5_1(conv5_1_out)
        conv5_2_out = self.conv5_2(conv5_1_out)
        conv5_2_out = self.bn5_2(conv5_2_out)
        conv5_2_out = self.relu5_2(conv5_2_out)
        maxpool5_out = self.maxpool5(conv5_2_out)
        # print("maxpool5:", maxpool5_out.shape)


        up6_out = self.up6(maxpool5_out)
        # print("up6",up6_out.shape)
        merge6_out = torch.cat([maxpool4_out, up6_out], dim=1)
        conv6_1_out = self.conv6_1(merge6_out)
        conv6_1_out = self.bn6_1(conv6_1_out)
        conv6_1_out = self.relu6_1(conv6_1_out)
        conv6_2_out = self.conv6_2(conv6_1_out)
        conv6_2_out = self.bn6_2(conv6_2_out)
        conv6_2_out = self.relu6_2(conv6_2_out)
        # print("conv6_3:",conv6_2_out.shape)
        #
        up7_out = self.up7(conv6_2_out)
        # print("up7:",up7_out.shape)
        merge7_out = torch.cat([maxpool3_out, up7_out],dim=1)
        # print("up7:", merge7_out.shape)
        conv7_1_out = self.conv7_1(merge7_out)
        conv7_1_out = self.bn7_1(conv7_1_out)
        conv7_1_out = self.relu7_1(conv7_1_out)
        conv7_2_out = self.conv7_2(conv7_1_out)
        conv7_2_out = self.bn7_2(conv7_2_out)
        conv7_2_out = self.relu7_2(conv7_2_out)
        # print("conv7_3:",conv7_2_out.shape)
        #
        up8_out = self.up8(conv7_2_out)
        merge8_out = torch.cat([maxpool2_out, up8_out], dim=1)
        conv8_1_out = self.conv8_1(merge8_out)
        conv8_1_out = self.bn8_1(conv8_1_out)
        conv8_1_out = self.relu8_1(conv8_1_out)
        conv8_2_out = self.conv8_2(conv8_1_out)
        conv8_2_out = self.bn8_2(conv8_2_out)
        conv8_2_out = self.relu8_2(conv8_2_out)
        # print("conv8_2:",conv8_2_out.shape)

        #
        up9_out = self.up9(conv8_2_out)
        merge9_out = torch.cat([maxpool1_out, up9_out], dim=1)
        conv9_1_out = self.conv9_1(merge9_out)
        conv9_1_out = self.bn9_1(conv9_1_out)
        conv9_1_out = self.relu9_1(conv9_1_out)
        conv9_2_out = self.conv9_2(conv9_1_out)
        conv9_2_out = self.bn9_2(conv9_2_out)
        conv9_2_out = self.relu9_2(conv9_2_out)
        # print("conv9_2:",conv9_2_out.shape)

        conv10_out = self.up10(conv9_2_out)
        # print("conv10:",conv10_out.shape)
        conv10_out=conv10_out+x
        conv10_out=self.maxpool10(self.conv10(conv10_out))
        conv11_out = self.maxpool11(self.conv11(conv10_out))
        conv12_out = self.maxpool12(self.conv12(conv11_out))
        # print(conv12_out.shape)
        conv13_out=self.relu13(self.conv13(conv12_out))
        conv13_out=conv13_out+conv12_out
        # print(conv13_out.shape)
        conv14_out = self.relu14(self.conv14(conv13_out))
        conv14_out = conv14_out + conv13_out
        conv15_out = self.relu15(self.conv15(conv14_out))
        conv15_out = conv15_out + conv14_out
        conv16_out = self.relu16(self.conv16(conv15_out))
        conv16_out = conv16_out + conv15_out
        conv17_out = self.relu17(self.conv17(conv16_out))
        conv18_out=self.conv18(conv17_out)
        conv19_out = self.conv19(conv18_out)
        conv20_out = self.conv20(conv19_out)
        return conv20_out
        #return maxpool3_out

maxim = unet()
input = torch.zeros(size=(1,1,128,160))
out = maxim(input)
print(out.shape)